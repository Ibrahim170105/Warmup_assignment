{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1-xP4laKAWbGRbSUq4VYwLBssqHeJiyyG",
      "authorship_tag": "ABX9TyOnuQehKlcZWrv7vmKhh8LS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibrahim170105/Warmup_assignment/blob/main/GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_add_cpu.cpp\n",
        "#include <iostream>\n",
        "#include <fstream>\n",
        "#include <chrono>\n",
        "using namespace std;\n",
        "\n",
        "int main() {\n",
        "    ifstream fin(\"input.txt\");\n",
        "    ofstream fout(\"output_cpu.txt\");\n",
        "\n",
        "    int n,m;\n",
        "    fin >> n >> m;\n",
        "\n",
        "    int size = n * m * sizeof(int);\n",
        "\n",
        "    int* h_A = new int[n * m];\n",
        "    int* h_B = new int[n * m];\n",
        "    int* h_C_cpu = new int[n * m];\n",
        "\n",
        "    for (int i = 0; i < n * m; i++) fin >> h_A[i];\n",
        "    for (int i = 0; i < n * m; i++) fin >> h_B[i];\n",
        "\n",
        "    auto cpu_start = chrono::high_resolution_clock::now();\n",
        "\n",
        "    for (int i = 0; i < n * m; i++)\n",
        "        h_C_cpu[i] = h_A[i] + h_B[i];\n",
        "\n",
        "    auto cpu_end = chrono::high_resolution_clock::now();\n",
        "    double cpu_time =\n",
        "        chrono::duration<double, milli>(cpu_end - cpu_start).count();\n",
        "\n",
        "    fout << \"Resultant Matrix:\\n\";\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        for (int j = 0; j < m; j++)\n",
        "            fout << h_C_cpu[i * m + j] << \" \";\n",
        "        fout << endl;\n",
        "    }\n",
        "\n",
        "    cout << \"Matrix Size: \" << n << \" x \" << m << endl;\n",
        "    cout << \"CPU Time (ms): \" << cpu_time << endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQKfYKfEORvL",
        "outputId": "9bffbf22-1091-4218-f725-e03f938d1c7c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_add_cpu.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ matrix_add_cpu.cpp -o matrix_cpu\n",
        "!./matrix_cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToonL4KZQSik",
        "outputId": "731adfde-eee3-4ef2-9f89-480b87dd47d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Size: 0 x 0\n",
            "CPU Time (ms): 9.3e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile matrix_add_gpu.cu\n",
        "#include <iostream>\n",
        "#include <fstream>\n",
        "#include <chrono>\n",
        "#include <cuda_runtime.h>\n",
        "#inlclude \"matrix_add_cpu.cpp\"\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/* ================= CUDA KERNEL ================= */\n",
        "__global__ void matrixAdd(int* A, int* B, int* C, int n, int m) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < n && col < m) {\n",
        "        int idx = row * m + col;\n",
        "        C[idx] = A[idx] + B[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "/* ================= MAIN ================= */\n",
        "int main() {\n",
        "    ifstream fin(\"input.txt\");\n",
        "\n",
        "    int n, m;\n",
        "    fin >> n >> m;\n",
        "\n",
        "    int size = n * m * sizeof(int);\n",
        "\n",
        "    // Host memory\n",
        "    int* h_A = new int[n * m];\n",
        "    int* h_B = new int[n * m];\n",
        "    int* h_C_cpu = new int[n * m];\n",
        "    int* h_C_gpu = new int[n * m];\n",
        "\n",
        "    for (int i = 0; i < n * m; i++) fin >> h_A[i];\n",
        "    for (int i = 0; i < n * m; i++) fin >> h_B[i];\n",
        "\n",
        "    /* ================= GPU MEMORY ================= */\n",
        "    int *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, size);\n",
        "    cudaMalloc(&d_B, size);\n",
        "    cudaMalloc(&d_C, size);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    /* ================= GPU TIMING ================= */\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 block(16, 16);\n",
        "    dim3 grid((m + 15) / 16, (n + 15) / 16);\n",
        "\n",
        "    matrixAdd<<<grid, block>>>(d_A, d_B, d_C, n, m);\n",
        "\n",
        "    cudaMemcpy(h_C_gpu, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float gpu_time;\n",
        "    cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "\n",
        "    /* ================= OUTPUT ================= */\n",
        "    cout << \"Matrix Size: \" << n << \" x \" << m << endl;\n",
        "    cout << \"GPU Time incl. transfer (ms): \" << gpu_time << endl;\n",
        "\n",
        "    ofstream fout(\"output_gpu.txt\");\n",
        "    fout << \"Result Matrix:\\n\";\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        for (int j = 0; j < m; j++)\n",
        "            fout << h_C_gpu[i * m + j] << \" \";\n",
        "        fout << endl;\n",
        "    }\n",
        "\n",
        "    /* ================= CLEANUP ================= */\n",
        "    delete[] h_A;\n",
        "    delete[] h_B;\n",
        "    delete[] h_C_cpu;\n",
        "    delete[] h_C_gpu;\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "O9qgMRNIQ9zr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4920dc08-7154-4747-8b0c-0e09d36ff610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_add_gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrix_add_gpu.cu -o matrix_add -arch=sm_75\n"
      ],
      "metadata": {
        "id": "k0AWB3Lj30k0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_R245vV3-wB",
        "outputId": "5e7d88c9-0c18-4faa-b48e-ebaa1c220056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Size: 1024 x 1024\n",
            "GPU Time incl. transfer (ms): 5.60246\n"
          ]
        }
      ]
    }
  ]
}